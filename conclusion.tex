\chapter{Conclusion}\label{C:con}
We found that differences between the native support offered by each language and the patterns used by developers of projects in that language were fairly frequent:
\begin{itemize}
	\item In Java, where classical inheritance is natively supported, 6.09\% of classes used forwarding patterns and 4.45\% of classes used delegation patterns.
	\item The C\# analysis showed that the vast majority of classes could be reimplemented in a delegation language with minimal need for modification. Just 0.07\% of classes contained constructor patterns which would exhibit unexpected behaviour without Uniform Identity.
	\item In JavaScript, where delegation is natively supported, 15\% of the functions in the median project were used to emulate class or method behaviour.
	\item In Lua, where delegation is natively supported, 17\% of all files contained patterns indicative of class behaviour.
\end{itemize}
From these numbers, it appears developers are more willing to use classical inheritance structures, thus ignoring native delegation. It is difficult to determine whether this is because classical inheritance is necessary for aspects of the projects or if its use is simply more common because developers find it more comfortable.
\newline

The further findings of this study involve a measurement of the difficulty involved in reimplementing projects built for classical inheritance into a language built for delegation. The main issues for this reimplementation are constructor patterns which are dependent on uniform identity. It was found, through the Java corpus analysis, that 13.83\% of classes made local calls from constructors and 2.05\% stored \java{this} from a constructor. Through the C\# corpus analysis, it was found that only around 10.3\% of calls to local methods from constructors are dispatched virtually at runtime. In C\#, only 0.17\% of classes contained a call from a constructor to a dynamically dispatched method.

\section{Limitations}
There are some innate limitations to the data which can be gathered through pattern matching against source code as carried out in this study. These limitations are largely a result of two factors. First, the inability to analyse code which is used by, but is not part of, the project; second, the disconnect between how often particular patterns are written (static frequency) and how often they are actually used during execution (dynamic frequency)~\cite{StaticAnalysisLimits}.

\subsection{Inaccessible External Code}
\label{InaccessibleCode}
When only analysing source files, it is difficult to collect information about pre-compiled units which are used by those source files at runtime~\cite{StaticAnalysisLimits}. An example of where this can limit the effectiveness of the analysis in this study is the absence of information about calls dispatched to a superclass when that superclass is defined in a pre-compiled library. If a source code file defines a class \code{A} which extends a class \code{B} where \code{B} is defined in a library with precompiled or otherwise inaccessible source code, we cannot see the details of the methods defined in \code{B}. This becomes an \textsl{}issue because it is no longer possible to determine whether a local call in \code{A} which targets a method defined on \code{B} will be dispatched statically or virtually because we cannot see the method declaration in \code{B}. This could cause unforeseen changes to the behaviour of the methods on \code{A} if another class \code{C} were to extend \code{A} and override methods from \code{B} which we were previously unaware were virtually dispatched calls.

\subsection{Static vs. Dynamic Frequency}
It is difficult, and in some cases impossible, to determine whether any particular class or method is actually used in the execution of a program, or to determine which classes and methods are used more frequently at runtime than others. For example, we might prefer give a different weighting in our analyses to the patterns used in unit test files on the assumption that these are typically written with the expectation that they will rarely need to undergo structural changes after they are written. The are also expected to be executed less frequently than other core functionality in general operation of the program.

\subsection{Incomplete Source Files}
There were cases of files in the JavaScript corpus which could not be parsed in isolation to form a valid syntax tree because they were not syntactically valid source. One example of this was a file which consisted of the majority of a valid JavaScript file but stopped short of the end, with a few other files in the same directory offering several different options for the final part of the code. The assumption here was that the files would be opened and appended at runtime but this was not possible to replicate in a study which operates on source code alone. This study ignored files which could not be compiled on their own, but it is possible that data was lost by ignoring files which expect to be concatenated to create valid programs.

\section{Future Work}
There are a few other methods of software analysis which can work around the issues outlined above to provide a clearer understanding of a software project than analysis based solely on source code.

\subsection{Analysis of Compiled Units}
Analysis of compiled units would help to mitigate the issues explained in section \ref{InaccessibleCode} where precompiled libraries are inaccessable to the analysis. Java and C\# both provide intermediate representations in the form of bytecode languages. For Java this is the Java Bytecode Language~\cite{JVMSpec} and for C\# this is Microsoft's Common Intermediate Language~\cite{CommonIntermediateLanguage}. An analysis of these intermediate representations would be useful because they both offer varied instructions for method calls depending on whether the call is virtually or statically dispatched. This helps to overcome the limitation of being unaware of how a call will be dispatched when analysing source code only.

\subsection{Analysis of Dynamic Frequency}
Analysing a program at runtime could provide useful information about how often particular patterns are used, as opposed to how often they are written. In JavaScript and Lua, a simple way to achieve this would be to modify commonly used libraries associated with classical inheritance implementations to add counters which record how often classes are created, modified or instantiated. In Java, a program called JVM Monitor~\cite{JVMMonitor} could be used to determine the invocation counts of methods which are of interest. This would allow code which is core to the functionality of the program to be weighted more heavily and code which is run relatively infrequently to be weighted more lightly.

\subsection{Measuring Intent}
Ideally, an empirical study of this nature would come with measures of the precision and recall of the algorithm. For this study, these measures would be dependent on comparing the patterns detected by the algorithms against the intent of the developer. Unfortunately, there is no easy way to accurately differentiate between a developer's intent and the patterns they use in their code. This issue is discussed in \textit{Does JavaScript Software Embrace Classes?} which describes the creation of the JSClassFinder tool~\cite{JSClassFinder}. Even when manually inspecting files and analysis results, it is often not possible to determine whether the result of the analysis is truly indicative of the developer's intent. For this reason, it is only possible to approximate the values of precision and recall based on some assumptions about whether certain patterns are, in fact, representative of the behaviours under analysis. Despite this, having estimated ranges of these precision and recall values could help to improve confidence in the research so would be valuable future work.