\chapter{Limitations and Future Work}\label{C:future}

\section{Limitations}
There are some innate limitations to the data which can be gathered through static analysis of source code as carried out in this study. These limitations are largely a result of two factors. First, the inability to analyse code which is used by, but is not part of, the project; second, the disconnect between how often particular patterns are written (static frequency) and how often they are actually used during execution (dynamic frequency).

\subsection{Inaccessible External Code}
\label{InaccessibleCode}
When only analysing source files, it is not possible to collect information about pre-compiled units which are used by those source files at runtime~\cite{StaticAnalysisLimits}. An example of where this can limit the effectiveness of the analysis in this study is the absence of information about calls dispatched to a superclass when that superclass is defined in a pre-compiled library. If a source code file defines a class \code{A} which extends a class \code{B} where \code{B} is defined in a library with precompiled or otherwise inaccessible source code, we cannot see the details of the methods defined in \code{B}. This becomes an issue because it is no longer possible to determine whether a local call in \code{A} which targets a method defined on \code{B} will be dispatched statically or virtually because we cannot see the method declaration. This could cause unforeseen changes to the behaviour of the methods on \code{A} if another class \code{C} were to extend \code{A} and override methods from \code{B} which we were previously unaware were virtually dispatched calls.

\subsection{Static vs. Dynamic Frequency}
It is generally not possible to determine whether any particular class or method is actually used in the execution of a program, or to determine which classes and methods are used more frequently at runtime than others. For example, we might prefer give a different weighting in our analyses to the patterns used in unit test files on the assumption that these are typically written with the expectation that they will rarely need to undergo structural changes after they are written. The are also expected to be executed less frequently than other core functionality in general operation of the program.

\subsection{Technical Limitations}
The Mono project in the C\# corpus had to be modified to allow the project to be analysed successfully due to technical constraints. As the Mono project sets out to provide an open source implementation of the necessary components of a C\# compiler, it contained a copy of the entire .NET core library. This library was over 500MB in size so, after conversion to syntax trees through ANTLR, could not be reasonably analysed within 16GB of ram. For this reason, and because none of the other projects in this study or in \cite{QualitasCorpus} included copies of the source of their libraries, the library was removed from the Mono project. Every project across the corpora studied will have some dependency on a library, even if it is just the languages core libraries, so removing a copy of these libraries from Mono will ensure its comparability with the rest of the analysed data.

\subsection{Incomplete Source Files}
There were cases of files in the JavaScript corpus which could not be parsed on their own to form a valid syntax tree because they were not syntactically sound. One example of this was a file which consisted of the majority of a valid JavaScript file but stopped short of the end, with a few other files in the same directory offering several different options for the final part of the code. The assumption here was that the files would be opened and appended at runtime but this was not possible to replicate in a study which operates on source code alone. This study ignored files which could not be compiled on their own, but it is possible that data was lost by ignoring files which expect to be concatenated to create valid programs.

\section{Future Work}
There are a few other methods of software analysis which can work around the issues outlined above to provide a clearer understanding of a software project than analysis based solely on source code.

\subsection{Analysis of Compiled Units}
Analysis of compiled units would help to mitigate the issues explained in section \ref{InaccessibleCode} where precompiled libraries are inaccessable to the analysis. Java and C\# both provide intermediate representations in the form of bytecode languages. For Java this is the Java Bytecode Language~\cite{JVMSpec} and for C\# this is Microsoft's Common Intermediate Language~\cite{CommonIntermediateLanguage}. An analysis of these intermediate representations would be useful because they both offer varied instructions for method calls depending on whether the call is virtually or statically dispatched. This helps to overcome the limitation of being unaware of how a call will be dispatched when analysing source code only.

\subsection{Analysis of Dynamic Frequency}
Analysing a program at runtime could provide useful information about how often particular patterns are used, as opposed to how often they are written. In JavaScript and Lua, a simple way to achieve this would be to modify commonly used libraries associated with classical inheritance implementations to add counters which record how often classes are created, modified or instantiated. In Java, a program called JVM Monitor~\cite{JVMMonitor} could be used to determine the invocation counts of methods which are of interest. This would allow code which is core to the functionality of the program to be weighted more heavily and code which is run relatively infrequently to be weighted more lightly.

\subsection{Measuring Precision and Recall}
As with the study \textit{Does JavaScript Software Embrace Classes?} which describes the creation of the JSClassFinder tool~\cite{JSClassFinder}, I had difficulty accurately measuring the exact precision and recall values for my analyses. This is largely because of the difficult in differentiating between a developer's intent and the patterns they use in their code. Even when manually inspecting files and analysis results, it is often not possible to determine whether the result of the analysis is truly indicative of the developer's intent. For this reason, it is only possible to approximate the values of precision and recall based on some assumptions about whether certain patterns are, in fact, representative of the behaviours under analysis. Despite this, having ranges of these precision and recall values could help to improve confidence in the research.



